{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import device\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput image(942,1716)\\n資料夾應該長這樣\\n|\\n|- model\\n|- Image-Label\\n|- Public_Image\\n|- SEG_Train_Datasets-|\\n|                     |- Train_Annotations\\n|                     |- Train_Images\\n|\\n|-segX8.ipynb\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "input image(942,1716)\n",
    "資料夾應該長這樣\n",
    "|\n",
    "|- model\n",
    "|- Image-Label\n",
    "|- Public_Image\n",
    "|- SEG_Train_Datasets-|\n",
    "|                     |- Train_Annotations\n",
    "|                     |- Train_Images\n",
    "|\n",
    "|-segX8.ipynb\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = os.path.join('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDs(Dataset):\n",
    "    def __init__(self, root='.', train_test='train', is_val=False, train_val_split=True, val_split_rate=0.8,\n",
    "                 transform=None):\n",
    "        self.filenames = []\n",
    "        self.labels = np.array([])\n",
    "        self.len = 0\n",
    "        self.transform = transform\n",
    "        self.train_test = train_test\n",
    "        if train_test == 'test':\n",
    "            file_path = os.path.join(root, 'Public_Image')\n",
    "        else:\n",
    "            file_path = os.path.join(root,  'SEG_Train_Datasets', 'Train_Images')\n",
    "            file_npy_path = os.path.join(root, 'NP_Label')\n",
    "            # data\n",
    "        self.filenames = [os.path.join(file_path, file) for file in os.listdir(file_path) if file.endswith('.jpg')]\n",
    "        self.labels = [os.path.join(file_npy_path, file) for file in os.listdir(file_npy_path) if file.endswith('.npy')]\n",
    "\n",
    "        self.filenames.sort()\n",
    "        self.labels.sort()\n",
    "        \n",
    "        if train_val_split:\n",
    "            split_nums = int(len(self.filenames) * val_split_rate)\n",
    "            self.filenames = self.filenames[split_nums:] if is_val else self.filenames[:split_nums]\n",
    "            self.labels = self.labels[split_nums:] if is_val else self.labels[:split_nums]\n",
    "        self.len = len(self.filenames)\n",
    "        # print(self.filenames[808])\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_fn = self.filenames[index]\n",
    "        image = Image.open(image_fn)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        images=[] #切割成8快\n",
    "        images.append(image[:, 0:512, 0:512])\n",
    "        images.append(image[:, 0:512, 512:1024])\n",
    "        images.append(image[:, 0:512, 1024:1536])\n",
    "        images.append(image[:, 0:512, 1204:1716])\n",
    "        images.append(image[:, 430:942, 0:512])\n",
    "        images.append(image[:, 430:942, 512:1024])\n",
    "        images.append(image[:, 430:942, 1024:1536])\n",
    "        images.append(image[:, 430:942, 1204:1716])\n",
    "        if self.train_test == 'test':\n",
    "            \n",
    "            return images\n",
    "\n",
    "        else:\n",
    "            label_name = self.labels[index]\n",
    "            label = np.load(label_name)\n",
    "            labels = []\n",
    "            labels.append(label[0:512, 0:512])\n",
    "            labels.append(label[0:512, 512:1024])\n",
    "            labels.append(label[0:512, 1024:1536])\n",
    "            labels.append(label[0:512, 1204:1716])\n",
    "            labels.append(label[430:942, 0:512])\n",
    "            labels.append(label[430:942, 512:1024])\n",
    "            labels.append(label[430:942, 1024:1536])\n",
    "            labels.append(label[430:942, 1204:1716])\n",
    "            return images, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\NP_Label\\00000000.npy\n",
      "(942, 1716)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(513, 512)\n",
      "(513, 512)\n",
      "(513, 512)\n",
      "(513, 512)\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 513, 512])\n",
      "torch.Size([3, 513, 512])\n",
      "torch.Size([3, 513, 512])\n",
      "torch.Size([3, 513, 512])\n"
     ]
    }
   ],
   "source": [
    "file_npy_path = os.path.join(root, 'NP_Label')\n",
    "labels = [os.path.join(file_npy_path, file) for file in os.listdir(file_npy_path) if file.endswith('.npy')]\n",
    "labels.sort()\n",
    "#print(labels)\n",
    "print(labels[0])\n",
    "label = np.load(labels[0])\n",
    "print(label.shape)\n",
    "\n",
    "a = []\n",
    "a.append(label[0:512, 0:512])\n",
    "a.append(label[0:512, 512:1024])\n",
    "a.append(label[0:512, 1024:1536])\n",
    "a.append(label[0:512, 1204:1716])\n",
    "a.append(label[429:942, 0:512])\n",
    "a.append(label[429:942, 512:1024])\n",
    "a.append(label[429:942, 1024:1536])\n",
    "a.append(label[429:942, 1204:1716])\n",
    "\n",
    "print(a[0].shape)\n",
    "print(a[1].shape)\n",
    "print(a[2].shape)\n",
    "print(a[3].shape)\n",
    "print(a[4].shape)\n",
    "print(a[5].shape)\n",
    "print(a[6].shape)\n",
    "print(a[7].shape)\n",
    "file_path = os.path.join(root,  'SEG_Train_Datasets', 'Train_Images')\n",
    "filenames = [os.path.join(file_path, file) for file in os.listdir(file_path) if file.endswith('.jpg')]\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "    ]\n",
    ")\n",
    "image_fn = filenames[1]\n",
    "image = Image.open(image_fn)\n",
    "image = transform1(image) \n",
    "b=[]\n",
    "b = []\n",
    "b.append(image[:, 0:512, 0:512])\n",
    "b.append(image[:, 0:512, 512:1024])\n",
    "b.append(image[:, 0:512, 1024:1536])\n",
    "b.append(image[:, 0:512, 1204:1716])\n",
    "b.append(image[:, 429:942, 0:512])\n",
    "b.append(image[:, 429:942, 512:1024])\n",
    "b.append(image[:, 429:942, 1024:1536])\n",
    "b.append(image[:, 429:942, 1204:1716])\n",
    "print(b[0].shape)\n",
    "print(b[1].shape)\n",
    "print(b[2].shape)\n",
    "print(b[3].shape)\n",
    "print(b[4].shape)\n",
    "print(b[5].shape)\n",
    "print(b[6].shape)\n",
    "print(b[7].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, model_pathname):\n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict()}\n",
    "    torch.save(state_dict, model_pathname, _use_new_zipfile_serialization=False)\n",
    "    print('model save to {}'.format(model_pathname))\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model, optimizer, model_pathname):\n",
    "    state_dict = torch.load(model_pathname)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    print('model load from {}'.format(model_pathname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SegDs(train_test='train', is_val=False, train_val_split=True, transform=transforms.Compose([\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "val_set = SegDs(train_test='train', is_val=True, train_val_split=True, transform=transforms.Compose([\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images in train set: 842\n",
      "# images in val set: 211\n"
     ]
    }
   ],
   "source": [
    "print('# images in train set:', len(train_set))  # Should print 947\n",
    "print('# images in val set:', len(val_set))  # Should print 106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 512, 512])\n",
      "torch.Size([2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            print(data[0].shape)\n",
    "            print(target[0].shape)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou_score(pred, labels):\n",
    "    '''\n",
    "    Compute mean IoU score over 6 classes\n",
    "    '''\n",
    "    mean_iou = 0\n",
    "    for i in range(2):\n",
    "        tp_fp = np.sum(pred == i)\n",
    "        tp_fn = np.sum(labels == i)\n",
    "        tp = np.sum((pred == i) * (labels == i))\n",
    "        if (tp_fp + tp_fn - tp) == 0:\n",
    "            iou = 0\n",
    "        else:\n",
    "            iou = tp / (tp_fp + tp_fn - tp)\n",
    "        mean_iou += iou / 2\n",
    "        # print('class #%d : %1.5f'%(i, iou))\n",
    "    # print('\\nmean_iou: %f\\n' % mean_iou)\n",
    "\n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "Device used: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(torch.__version__)\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print('Device used:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, lr=1e-4, is_val=False):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=num_epochs, eta_min=lr * 0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_mIoU = 0\n",
    "        train_loss = 0\n",
    "        train_pred = np.array([], dtype=bool)\n",
    "        train_target = np.array([], dtype=bool)\n",
    "        model.train()  # Important: set training mode\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            for index in range(8):\n",
    "                data[index], target[index] = data[index].to(device), target[index].to(device, dtype=torch.int64)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data[index])\n",
    "                pred = out['out']\n",
    "                aux = out['aux']\n",
    "                loss = criterion(pred, target[index]) + criterion(aux, target[index])\n",
    "                # pred = model(data)\n",
    "                # loss = criterion(pred, target)\n",
    "                train_loss += loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                iteration += 1\n",
    "                # get train mIoU\n",
    "                if batch_idx % 50 == 0 and batch_idx != 0:\n",
    "                    print('{}/{}, loss: {:.4f}'.format(batch_idx * batch_size, len(train_loader.dataset), train_loss / 50))\n",
    "                    train_loss = 0\n",
    "                if batch_idx == 0:\n",
    "                    train_pred = pred.max(dim=1)[1].detach().cpu().numpy().astype('bool')\n",
    "                    train_target = target[index].detach().cpu().numpy().astype('bool')\n",
    "                else:\n",
    "                    train_pred = np.concatenate((train_pred, pred.max(dim=1)[1].detach().cpu().numpy().astype('bool')), axis=0, dtype=bool)\n",
    "                    train_target = np.concatenate((train_target, target[index].detach().cpu().numpy().astype('bool')), axis=0, dtype=bool)\n",
    "        print('train_pred.shape, train_target.shape',train_pred.shape, train_target.shape)\n",
    "        scheduler.step()\n",
    "        train_mIoU = mean_iou_score(train_pred, train_target)\n",
    "        if is_val:\n",
    "            val_mIoU = test(model, epoch)\n",
    "            print('Train Epoch: {}, train_mIoU = {:.4f}, val_mIoU = {:.4f}'.\n",
    "                  format(epoch, train_mIoU, val_mIoU))\n",
    "            if epoch % 1 == 0:\n",
    "                save_model(model, optimizer,\n",
    "                           './model/seg_model_epoch{}_lr_{:.6f}_l2_{}_vgg16_fcn_train{:.3f}_val{:.3f}.pth'\n",
    "                           .format(epoch + 1, optimizer.param_groups[0]['lr']\n",
    "                                   , optimizer.param_groups[0]['weight_decay'], train_mIoU, val_mIoU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch=0):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()  # Important: set evaluation mode\n",
    "    test_loss = 0\n",
    "    test_mIoU = 0\n",
    "    test_pred = np.array([], dtype=bool)\n",
    "    test_target = np.array([], dtype=bool)\n",
    "    loader = val_loader\n",
    "    with torch.no_grad():  # This will free the GPU memory used for back-prop\n",
    "        count = 0\n",
    "        for batch_index, (data, target) in enumerate(tqdm(loader)):\n",
    "            for index in range(8):\n",
    "                data[index], target[index] = data[index].to(device), target[index].to(device, dtype=torch.int64)\n",
    "                # pred = model(data)\n",
    "                pred = model(data[index])['out']\n",
    "                test_loss += criterion(pred, target[index]).item()  # sum up batch loss\n",
    "                if batch_index == 0:\n",
    "                    test_pred = pred.max(dim=1)[1].detach().cpu().numpy().astype('bool')\n",
    "                    test_target = target[index].detach().cpu().numpy().astype('bool')\n",
    "                else:\n",
    "                    test_pred = np.concatenate((test_pred, pred.max(dim=1)[1].detach().cpu().numpy().astype('bool')), axis=0, dtype=bool)\n",
    "                    test_target = np.concatenate((test_target, target[index].detach().cpu().numpy().astype('bool')), axis=0, dtype=bool)\n",
    "        test_mIoU = mean_iou_score(test_pred, test_target)\n",
    "        # print(len(loader), len(loader.dataset))\n",
    "        # test_loss /= len(loader)\n",
    "    return test_mIoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLabV3(\n",
      "  (backbone): IntermediateLayerGetter(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): DeepLabHead(\n",
      "    (0): ASPP(\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (4): ASPPPooling(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (aux_classifier): FCNHead(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "deeplab = deeplabv3_resnet50(pretrained=False, aux_loss=True).cuda()\n",
    "deeplab.classifier[-1] = nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "deeplab.aux_classifier[-1] = nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "print(deeplab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't load mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 50/421 [01:56<16:51,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/842, loss: 1.9451\n",
      "100/842, loss: 0.0045\n",
      "100/842, loss: 0.0011\n",
      "100/842, loss: 0.0013\n",
      "100/842, loss: 0.0015\n",
      "100/842, loss: 0.0031\n",
      "100/842, loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 51/421 [01:59<17:04,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/842, loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 100/421 [04:42<20:13,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/842, loss: 0.9807\n",
      "200/842, loss: 0.0077\n",
      "200/842, loss: 0.0006\n",
      "200/842, loss: 0.0007\n",
      "200/842, loss: 0.0011\n",
      "200/842, loss: 0.0071\n",
      "200/842, loss: 0.0011\n",
      "200/842, loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 150/421 [08:24<24:35,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/842, loss: 0.8717\n",
      "300/842, loss: 0.0004\n",
      "300/842, loss: 0.0009\n",
      "300/842, loss: 0.0004\n",
      "300/842, loss: 0.0004\n",
      "300/842, loss: 0.0007\n",
      "300/842, loss: 0.0006\n",
      "300/842, loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 200/421 [13:08<22:27,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/842, loss: 0.7961\n",
      "400/842, loss: 0.0039\n",
      "400/842, loss: 0.0007\n",
      "400/842, loss: 0.0008\n",
      "400/842, loss: 0.0010\n",
      "400/842, loss: 0.0015\n",
      "400/842, loss: 0.0010\n",
      "400/842, loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 250/421 [17:55<17:05,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/842, loss: 0.6729\n",
      "500/842, loss: 0.0050\n",
      "500/842, loss: 0.0162\n",
      "500/842, loss: 0.0266\n",
      "500/842, loss: 0.0026\n",
      "500/842, loss: 0.0025\n",
      "500/842, loss: 0.0016\n",
      "500/842, loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 300/421 [23:26<14:58,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/842, loss: 0.6149\n",
      "600/842, loss: 0.0048\n",
      "600/842, loss: 0.0091\n",
      "600/842, loss: 0.0043\n",
      "600/842, loss: 0.0003\n",
      "600/842, loss: 0.0019\n",
      "600/842, loss: 0.0044\n",
      "600/842, loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 350/421 [29:58<09:57,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/842, loss: 0.6805\n",
      "700/842, loss: 0.0028\n",
      "700/842, loss: 0.0015\n",
      "700/842, loss: 0.0008\n",
      "700/842, loss: 0.0009\n",
      "700/842, loss: 0.0023\n",
      "700/842, loss: 0.0010\n",
      "700/842, loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 400/421 [37:30<03:18,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/842, loss: 0.5073\n",
      "800/842, loss: 0.0006\n",
      "800/842, loss: 0.0003\n",
      "800/842, loss: 0.0006\n",
      "800/842, loss: 0.0009\n",
      "800/842, loss: 0.0022\n",
      "800/842, loss: 0.0001\n",
      "800/842, loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 421/421 [40:54<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pred.shape, train_target.shape (6722, 512, 512) (6722, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-8f578a8fa390>:10: RuntimeWarning: overflow encountered in long_scalars\n",
      "  if (tp_fp + tp_fn - tp) == 0:\n",
      "<ipython-input-11-8f578a8fa390>:13: RuntimeWarning: overflow encountered in long_scalars\n",
      "  iou = tp / (tp_fp + tp_fn - tp)\n",
      "100%|██████████| 105/105 [02:47<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, train_mIoU = 0.6266, val_mIoU = 0.5145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 50/421 [01:55<16:29,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/842, loss: 0.5886\n",
      "100/842, loss: 0.0028\n",
      "100/842, loss: 0.0010\n",
      "100/842, loss: 0.0008\n",
      "100/842, loss: 0.0021\n",
      "100/842, loss: 0.0024\n",
      "100/842, loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 51/421 [01:57<16:37,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/842, loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 86/421 [03:46<14:42,  2.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-50ed120de741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeeplab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e3dfe333fe3b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, num_epochs, lr, is_val)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;31m# get train mIoU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             F.adamw(params_with_grad,\n\u001b[0m\u001b[0;32m    138\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    deeplab.load_state_dict('./seg_model_epoch10_lr_0.000051_l2_0.0005_vgg16_fcn_train0.954_val0.804.pth')\n",
    "except:\n",
    "    print(\"can't load mode\")\n",
    "    pass\n",
    "\n",
    "train(deeplab.to(device), num_epochs=50, lr=1e-4, is_val=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
